import collections
import datetime
import json
import os
import pickle
import shutil
import zipfile
import tempfile
from operator import itemgetter
import multiprocessing

from imblearn.over_sampling import SMOTE
from dateutil.relativedelta import relativedelta
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support
from sklearn.feature_extraction import DictVectorizer
from tqdm import tqdm
import numpy as np
import shap
from joblib import Parallel, delayed

from .util.report import Report


def _get_infrequent_phrases(features_set, threshold_rate=0.03):
    """Get infrequent phrases on given dataset

    Args:
        features_set (iter): list of feature's dict
        threshold_rate (float, optional): Defaults to 0.03.

    Returns:
        set: set of infrequent phrase features
    """
    phrases = [f for fs in features_set for f in fs if f.startswith('C:kp__')]
    phrases = collections.Counter(phrases).most_common()
    n_cut = int(len(phrases) * threshold_rate)
    return set([p for p, _ in phrases[-n_cut:]])


def make_batchdata(dataset, exploited_cves,
                   begin_date=None, end_date=None):
    """Make batch dataset for training production model

    Args:
        dataset (list): file path to dataset
        exploited_cves (set): set of exploited cves
        begin_date (str, optional): Begin date as `2016-01-01`,
                                    Defaults to '2020-04-01''.
        end_date (str, optional): End date as `2020-01-01`,
                                  Defaults to '2020-04-01'.

    Returns:
        tuple: triple of cve, features, and target
    """
    cve2features = {d['id']: d['features'] for d in dataset
                    if begin_date is None or begin_date <= d['date']
                    if end_date is None or d['date'] < end_date}

    infreq_phrases = _get_infrequent_phrases(cve2features.values())
    cve2features = {cve: {f: v
                          for f, v in features.items()
                          if f not in infreq_phrases}
                    for cve, features in cve2features.items()}

    train_cves = sorted(cve2features.keys())
    train_x = [cve2features[cve] for cve in train_cves]
    train_y = [int(cve in exploited_cves) for cve in train_cves]
    return (train_cves, train_x, train_y)


def make_onlinedata(dataset, exploited_cves, is_move_begin_train=False,
                    begin_date=None, end_date=None,
                    init_train_range=relativedelta(years=1),
                    test_ragne=relativedelta(months=6),
                    move_width=relativedelta(months=6)):
    """Make online dataset to evaluate models

    Args:
        dataset (list): file path to dataset
        exploited_cves (set): set of exploited cves
        is_move_begin_train (bool):
            If true begin date of training is move ```move_width``` dates
        begin_date (str, optional):
            Begin date as `2016-01-01`, Defaults to '2020-04-01''.
        end_date (str, optional):
            End date as `2020-01-01`, Defaults to '2020-04-01'.
        init_train_range (dateutil.relativedelta):
            Date range for initial training. Defaults to 1 year.
        test_ragne (dateutil.relativedelta):
            Date range for test. Defaults to 6 months.
        move_width (dateutil.relativedelta):
            Date range to move next iteration. Defaults to 6 months.

    Returns:
        list: list of (cve, features, and target)
    """
    f = lambda dt: dt.strftime('%Y-%m-%d')  # datetime to str
    rf = lambda s: datetime.datetime.strptime(s, '%Y-%m-%d')  # str to datetime

    dates = sorted([d['date'] for d in dataset])
    if begin_date is None:
        begin_date = dates[0][:8] + '01'
    if end_date is None:
        end_date = f(rf(dates[-1]) + move_width)[:8] + '01'

    cve2date = {d['id']: d['date'] for d in dataset
                if begin_date <= d['date'] and d['date'] < end_date}

    cve2features = {d['id']: d['features'] for d in dataset
                    if begin_date <= d['date'] and d['date'] < end_date}

    infreq_phrases = _get_infrequent_phrases(cve2features.values())
    cve2features = {cve: {f: v
                          for f, v in features.items()
                          if f not in infreq_phrases}
                    for cve, features in cve2features.items()}

    datasets = []
    begin_train = rf(begin_date)
    begin_test = begin_train + init_train_range
    end_test = begin_test + test_ragne

    def make_data(cves):
        x = [cve2features[cve] for cve in cves]
        y = [int(cve in exploited_cves) for cve in cves]
        return x, y

    while True:
        train_cves = [cve for cve, date in cve2date.items()
                      if f(begin_train) <= date and date < f(begin_test)]
        train_x, train_y = make_data(train_cves)

        test_cves = [cve for cve, date in cve2date.items()
                     if f(begin_test) <= date and date < f(end_test)]
        test_x, test_y = make_data(test_cves)

        if len(train_cves) == 0 or len(test_cves) == 0:
            break

        datasets.append(((train_cves, train_x, train_y),
                         (test_cves, test_x, test_y)))

        if is_move_begin_train:
            begin_train += move_width
        begin_test += move_width
        end_test += move_width

        if f(begin_test) >= end_date:
            break
    return datasets


def load_dataset(path_dataset):
    """Load dataset from a JSON file

    Args:
        path_dataset (str): file path to a dataset

    Returns:
        list: list of features's dictionary
    """
    with open(path_dataset, 'r', encoding='utf-8') as fd:
        dataset = json.load(fd)
    return dataset


class Model(object):
    """Exploit Prediction Model
    """

    @classmethod
    def load_from(cls, filename):
        """Load from pretrained model

        Args:
            filename (str): path to model file

        Returns:
            model.Model: instance of Model
        """
        model = cls()
        model.model = lgb.Booster(model_file=filename)
        model.model.params["objective"] = "binary"
        return model

    def train(self, x, y, validation_data=None,
              early_stopping_rounds=0,
              params=None):
        """Train a new model

        Args:
            x (array, sparse matix): training features
            y (array): training target
            validation_data (tuple, optional):
                pair of validation x and y. Defaults to None.
            early_stopping_rounds (int, optional): Defaults to 0.
            params (dict, optional):
                options are passed to ```lgb.train```. Defaults to None.

        Raises:
            Exception: [description]
        """

        if validation_data is None and early_stopping_rounds == 0:
            raise Exception('Require validation data for early stopping')

        dtrain = lgb.Dataset(x, y, params={'verbose': -1})
        valid_x, valid_y = validation_data
        dval = lgb.Dataset(valid_x, valid_y, params={'verbose': -1})

        if params is None:
            params = {
                "objective": "binary",
                "metric": "binary_logloss",
                "boosting_type": "gbdt",
                'verbose': -1,
            }

        self.model = lgb.train(params, dtrain,
                               valid_sets=dval,
                               early_stopping_rounds=early_stopping_rounds,
                               verbose_eval=False)

    def predict(self, x):
        """Performe classification on sample in x

        Args:
            x (array, sparse matix): training features

        Returns:
            array: probabilities for each examples
        """
        return np.rint(self.model.predict(x))

    def predict_prob(self, x):
        """Performe classification on sample in x

        Args:
            x (array, sparse matix): training features

        Returns:
            array: class label (binary) for each examples
        """
        return self.model.predict(x)

    def batch_explain(self, x, feature_naems, batch_size=100,
                      n_cpu=int(multiprocessing.cpu_count() / 2)):
        """Get local explanations using SHAP

        Args:
            x (array, sparse matix): training features
            feature_naems (list): list of feature names
            batch_size (int, optional): Defaults to 100.
            n_cpu ([type], optional):
                Defaults to `int(multiprocessing.cpu_count() / 2)`.

        Returns:
            list: list of dictionary of explnations
        """
        explanations = []
        total = int(x.shape[0] / batch_size)

        batches = [x[i: i + batch_size]
                   for i in range(0, x.shape[0], batch_size)]
        if n_cpu is None:
            n_cpu = int(multiprocessing.cpu_count() / 2)
        with tqdm(total=total) as t:
            step = 100
            i = 0
            while i < total:
                with Parallel(n_jobs=n_cpu) as parallel:
                    exps = parallel([delayed(self.explain)(batch,
                                                           feature_naems)
                                    for batch in batches[i:i + step]])
                    for exp in exps:
                        explanations.extend(exp)
                    t.update(step)
                    i += step

        return explanations

    def explain(self, x, feature_names, threshold=10, round_at=3):
        """Get local explanations using SHAP

        Args:
            x (array, sparse matix): training features
            feature_naems (list): list of feature names
            threshold (int, optional):
                Get best/worst features. Defaults to 10.
            round_at (int, optional): Defaults to 3.

        Returns:
            list: list of dictionary of explnations
        """
        explainer = shap.TreeExplainer(self.model)
        x_ary = x.toarray()

        # Two SHAP vlaue for class 1 and 0 are returned, and
        # this method uses SHAP value for positive class.
        shap_values = explainer.shap_values(x_ary)

        preds = [{f'{n}=={v}': round(float(p), round_at)
                  for v, n, p in zip(x, feature_names, ps)
                  if p != 0.}
                 for x, ps in zip(x_ary, shap_values[1])]

        def filter_n_best_and_worst(dic, n_best):
            best = dict(sorted(dic.items(),
                               key=itemgetter(1),
                               reverse=True)[:n_best])
            worst = dict(sorted(dic.items(),
                                key=itemgetter(1),
                                reverse=False)[:n_best])
            best.update(worst)
            return best
        preds = [filter_n_best_and_worst(pred, threshold) for pred in preds]

        return preds

    def save(self, filename):
        """Save model into a file

        Args:
            filename (str): path to store model
        """
        self.model.save_model(filename)


def build_model(dataset, random_state=42):
    """Build model from given training dataset

    Args:
        dataset (triple): triple of cve, features, and target
        random_state (int, optional): Defaults to 42.

    Returns:
        (vectorizer, model.Model): vectorizer and trained model
    """
    train_cves, train_x, train_y = dataset
    vectorizer = DictVectorizer(separator=':')
    train_x = vectorizer.fit_transform(train_x)

    smote = SMOTE(random_state=random_state)
    train_x, train_y = smote.fit_resample(train_x, train_y)
    train_x, valid_x, train_y, valid_y =\
        train_test_split(train_x, train_y,
                         test_size=0.25, random_state=random_state)

    model = Model()
    model.train(train_x, train_y,
                validation_data=(valid_x, valid_y),
                early_stopping_rounds=5)

    return vectorizer, model


def validate(dataset, random_state=42):
    """Validate model precision, recall, and F score

    Args:
        dataset (list): list of (cve, features, and target)
        random_state (int, optional): [description]. Defaults to 42.

    Returns:
        report.Report: validation results
    """
    report = Report()

    for (_, train_x, train_y), (_, test_x, test_y) in tqdm(dataset):
        vectorizer = DictVectorizer(separator=':')
        train_x = vectorizer.fit_transform(train_x)

        train_x, valid_x, train_y, valid_y =\
            train_test_split(train_x, train_y,
                             test_size=0.25, random_state=random_state)
        smote = SMOTE(random_state=random_state)
        train_x, train_y = smote.fit_resample(train_x, train_y)

        model = Model()
        model.train(train_x, train_y,
                    validation_data=(valid_x, valid_y),
                    early_stopping_rounds=5)

        pred_y = model.predict(train_x)
        p, r, f, _ =\
            precision_recall_fscore_support(train_y, pred_y, average='binary')
        report.add_train_scores(p, r, f)

        pred_y = model.predict(valid_x)
        p, r, f, _ =\
            precision_recall_fscore_support(valid_y, pred_y, average='binary')
        report.add_valid_scores(p, r, f)

        test_x = vectorizer.transform(test_x)
        pred_y = model.predict(test_x)
        p, r, f, _ =\
            precision_recall_fscore_support(test_y, pred_y, average='binary')
        report.add_test_scores(p, r, f)

    return report


def save_model(dir_path, vectorizer, classifier):
    """Save model and vectorizer into one zip file

    Args:
        dir_path (stc): directory name to store model
        vectorizer (vectorizer): sklearn's vectorizer
        classifier (model.Model): trained model
    """
    with open(os.path.join(dir_path, 'vectorizer.pk'), 'wb') as fd:
        pickle.dump(vectorizer, fd)
    classifier.save(os.path.join(dir_path, 'model'))

    shutil.make_archive(dir_path, 'zip', root_dir=dir_path)
    shutil.rmtree(dir_path)


def load_model(file_path):
    """Load model and vectorizer

    Args:
        file_path (str): file path to a model zip file

    Returns:
        (vectorizer, model.Model): vectorizer and trained model
    """
    with zipfile.ZipFile(file_path) as zfd:
        with zfd.open('vectorizer.pk', 'r') as fd:
            vectorizer = pickle.load(fd)

        with tempfile.TemporaryDirectory() as dname:
            zfd.extract('model', path=dname)
            path_model = os.path.join(dname, 'model')
            classifier = Model.load_from(path_model)
    return vectorizer, classifier


def write_predict_results(cves, pred_y, explanations, out_dir):
    """Writes prediction results for data feed

    The length of cves, pred_y, and explanations must be equal.

    Args:
        cves (list): list of CVEs
        pred_y (list): list of probabilites
        explanations (list): list of dictionary of explnations
        out_dir (str): directory path to store results
    """
    timestamp = datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S.%f')
    preds = {cve: {'score': round(y, 3), 'explanations': e,
                   'update_datetime': timestamp}
             for cve, y, e in zip(cves, pred_y, explanations)}

    year2data = collections.defaultdict(dict)
    for cve, data in preds.items():
        year = cve[4:8]
        year2data[year][cve] = data
        path_year = os.path.join(out_dir, year)
        if not os.path.exists(path_year):
            os.mkdir(path_year)
        with open(os.path.join(path_year, f'{cve}.json'), 'w') as fd:
            json.dump(data, fd, indent=4)

    for year, data in year2data.items():
        path_year = os.path.join(out_dir, year)
        with open(os.path.join(path_year, f'CVE-{year}.json'), 'w') as fd:
            json.dump(data, fd, indent=4)
